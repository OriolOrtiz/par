require '../rubytex'

documentclass "article", options: "a4paper,11pt"

# Packages
usepackage "inputenc", options: "utf8"
usepackage "color", options: "usenames,dvipsnames"
usepackage "graphicx"
usepackage "caption", options: "justification=centering,labelfont=bf"
usepackage "listings"
usepackage "hyperref", options: "hidelinks"

document "Lab 2: Geometric decomposition – solving the heat equation",
  "1202", "Parallelism", ["Héctor Ramón Jiménez", "Alvaro Espuña Buxo"],
  "Facultat d'Informàtica de Barcelona" do

  section "Analysis of dependences for the heat equation"
  p "The analysis of the dependencies caused by the proposed task decomposition for the three solvers of the
  heat equation has been done using Tareador. Dependences appear when a task reads a memory position
  previously written by another task. Some dependences may impose task ordering constraints while other
  may impose data access constraints. For solving the heat equation three different solvers have been used,
  each with different dependence patterns. For the Jacobi solver, {... describe the dependences in Jacobi
  here...}. In the parallelization with OpenMP, we plan to guarantee these dependences { ... describe here
  how to enforce the dependences in Jacobi ...}. { ... Other paragraphs for Gauss-Seidel solver ...}.
  The following table summarizes the predicted speed–up for the parallel execution for the two solvers,
  with 2, 4, 8 and 16 processors with respect to the simulation with just 1 processor. {... include table
  generated from the Dimemas simulations ...}."

  section "OpenMP parallelization and execution analysis"

  enumerate do
    question "Briefly comment the parallelization with OpenMP that has been done for the two solvers."

    question "Plot the speedup achieved by the OpenMP parallel version, with respect to sequential execution
    time, for the two solvers. Comment the results that are obtained and justify the scalability that is
    obtained. Include Paraver timelines in order to support your explanation."

    question "In the parallelization of Gauss-Seidel, analyze the impact on the parallel execution time of the
    block size ``\\texttt{by}'' (or equivalently the number of blocks ``\\texttt{nby}'')
    \\footnote{The resulting image should be the same.}. For example try with
    \\texttt{nby=2*nbx, nby=4*nbx, ...} Is there any performance impact? Is there an optimal point?
    Justify your answer."

    class Float
      def to_s
        "%.3f" % self # Just 3 decimals please
      end
    end

    rows = {
      "2*nbx" => [6.481, 4.764, 3.945, 4.503, 7.939],
      "4*nbx" => [6.471, 4.484, 3.667, 7.330, 14.437],
      "8*nbx" => [6.190, 4.350, 6.505, 13.053, 19.018],
      "16*nbx" => [6.351, 5.862, 8.015, 11.552, 17.799],
      "32*nbx" => [5.202, 13.510, 18.078, 21.471, "-"]
    }

    figure do
      tabular "| l || c | c | c | c | c |" do
        head "\\texttt{nby}", "1 thread", "2 threads", "4 threads", "8 threads", "16 threads"
        hline
        rows.each { |nby, values| row "\\texttt{#{nby}}", *values }
        hline
      end
      caption "Impact of the number of blocks ``\\texttt{nby}''. Time is in seconds."
    end

    br
    p "The number of blocks ``\\texttt{nby}'' has an obvious performance impact, affecting
      considerably the parallel execution times. This is because the ``\\texttt{nby}'' value is
      directly related with the number of performed flushes. There are going to be at least \\texttt{nby*nbx}
      flushes to mark each block as processed. To this flushes we have to add the flushes that each thread
      performs when it's waiting its dependencies to be processed. Thus, the optimal value is going to be
      one that finds a balance between these two types of flushes (one that keeps ``\\texttt{nby}''
      reasonably low but allowing to solve the dependencies quickly). In the obtained results this value
      seems to be \\texttt{4*nbx} with $4$ threads."
  end
end
