require './rubytex'

documentclass "article", options: "a4paper,11pt"

# Packages
usepackage "inputenc", options: "utf8"
usepackage "color", options: "usenames,dvipsnames"
usepackage "graphicx"
usepackage "caption", options: "justification=centering,labelfont=bf"
usepackage "listings"

# Variables
assignatura = "Parallelism"
titol = "Second deliverable"
autors = ["Héctor Ramón Jiménez", "Alvaro Espuña Buxo"]

# Commands
def blueline(line); textcolor "blue", line; end
def hrule(); rule "\\linewidth", "0.5mm"; end
def bold(text); textbf text; end
def math(); puts "\\["; yield; puts "\\]"; end
def equals(); puts "="; end

$problem_counter = 0
def question(text)
  setcounter "enumi", $problem_counter
  $problem_counter += 1
  item; bold text
end

def answer()
  br
  yield
end

def figure(options: "h!")
  env("figure", options: options) { yield }
end

def graphic(path, options: "width=1.0\\textwidth")
  includegraphics path, options: options
end

document do
  titlepage do
    center do
      textsc "\\Large #{assignatura}"; br
      texttt 1202; br 1.5
      hrule; br 0.4
      wrap { huge; bfseries; puts titol; br 0.4 }
      hrule; br 2.5
      
      minipage "0.4\\textwidth" do
        flushleft { large; puts autors[0] }
      end
      
      minipage "0.4\\textwidth" do
        flushright { large; puts autors[1] }
      end

      vfill
      wrap { large; today }
      br
      wrap { large; texttt "Facultat d'Informàtica de Barcelona" }
    end
  end

  section "Parallelization overheads", special: true
  enumerate do
    question "Which is the overhead associated with the activation
    of a \\texttt{parallel} region in OpenMP? Is it constant?  Reason the answer
    based on the results reported by the \\texttt{ompparallel} code and the the
    trace visualized with Paraver."

    figure do
      graphic "overheads/ompparallel_time.pdf"
      caption "Overheads of the activation of parallel regions"
    end

    answer do
      puts "The figure above shows that the activation of the \\texttt{parallel}
      region has a total overhead that \\textbf{grows with the number of threads}. It shows that
      the overhead per thread remains constant ($\\approx0.333\\mu s$), which means that the total overhead grows
      linearly."
      br
      puts "Paraver shows clearly how the main thread needs to create every other thread
      \\textbf{independently} and, at the end, join and terminate all of them. Thus, the time of
      the creation and termination depends on the number of threads to create/terminate."
    end

    question "Which is the minimum overhead associated with the
    execution of critical regions in OpenMP?"

    answer do
      puts "The minimum overhead occurs when a single thread is used. When there is only
      one thread it can \\texttt{lock} the region at any moment without waiting. However,
      \\texttt{lock} and \\texttt{unlock} take time even if there are no other threads involved.
      This means that critical regions with one thread have an overhead compared to not using
      them."
      br
      puts "To calculate the minimum overhead per critical region executed we can use the time (in $ns$) of
      \\texttt{dotprod\\_serial} and \\texttt{dotprod\\_mutex\\_everytime} with one single thread:"

      $critical_1 = (1.079 - 0.315) * 10**9 / 2**26
      math do
        puts "T_{critical_1}"
        equals
        frac "T_{1\\_mutex\\_everytime} - T_{1\\_serial}", "N_{critical\\_regions}"
        equals
        frac "1.079 - 0.315", "2^{26}"
        cdot "10^9"
        equals
        puts "%.3f ns" % [$critical_1]
      end
    end

    question "In the presence of lock conflicts and true sharing
    (as it happens in dotprod mutex everytime), how the overhead
    associated with critical increases with the number of processors?
    How this overhead is decomposed? Reason the answer based on the
    results visualized with Paraver."

    answer do
      center do
        tabular "| l || c |" do
          head "Number of threads", "Time (s)"
          hline
          row 1, 1
          row 2, 7
          row 4, 24
          row 8, 35
          hline
        end
      end

      puts "As the table above shows, the overhead grows far from a linear way.
      The chances of a successful \\texttt{lock} decrease as the number of threads grows.
      Paraver shows that every thread spends approximately, when using 4 or 8 threads,
      a \\textbf{60\\%} of the execution time in the \\texttt{lock} phase when only stays
      \\texttt{locked} a \\textbf{1\\%} of it."
      br
      puts "We can calculate the overhead associated with the critical regions in function of the number of threads.
      If we use $P$ threads then the work performed by \\texttt{dotprod\\_serial} is shared equitatively. 
      We have to add to the equation the overhead of creation/termination of the additional threads:"
      math do
        puts "T_{critical_P}"
        equals
        frac "T_{P_{mutex\\_everytime}} - \\frac{T_{P_{serial}}}{P} - 0.333 \\cdot (P-1)", "N_{critical\\_regions}"
      end
      puts "For example, with $P = 8$:"
      
      $critical_8 = (35.447 - (0.315 / 8) - 0.333 * 7) * 10**9 / 2**26
      math do
        puts "T_{critical_8}"
        equals
        frac "35.447 - \\frac{0.315}{8} - 0.333 \\cdot 7", "2^{26}"
        cdot "10^9"
        equals
        puts "%.3f ns" % [$critical_8]
      end

      puts "This is actually $\\frac{T_{critical_8}}{T_{critical_1}} - 1 = %.3f$ times more overhead
      than using one thread!" % [$critical_8 / $critical_1 - 1]
    end

    clearpage

    question "In the presence of \\texttt{false sharing} (as it happens in
    dotprod vectorsum), which is the additional average access latency
    that you observe to memory? Which causes this increase in the memory
    access time? Reason the answer based on the results visualized with
    Paraver."

    answer do
      puts "The additional average access latency to memory can be calculated using the time of
      the versions with and without \\texttt{false sharing}:"

      $m = (0.243 - 0.069) * 10**9 / (2**26 / 8)
      math do
        puts "T_m"
        equals
        frac "T_{no\\_padding} - T_{padding}", "\\frac{N_{accesses}}{P}"
        equals
        frac "0.243 - 0.069", "\\frac{2^{26}}{8}"
        cdot "10^9"
        equals
        puts "%f ns" % [ $m ]
      end

      puts "These are the Paraver histograms that show noticeable differences:"

      figure do
        graphic "overheads/Total_number_of_L3D_accesses@dotprod_vectorsum-i.png"
        graphic "overheads/Total_number_of_L3D_accesses@dotprod_vectorsum_padding-i.png"
        caption "Differences in level 3 cache accesses"
      end

      figure do
        graphic "overheads/Total_number_of_snoop_requests@dotprod_vectorsum-i.png"
        graphic "overheads/Total_number_of_snoop_requests@dotprod_vectorsum_padding-i.png"
        caption "Differences in snoop requests"
      end

      puts "The histograms show that \\texttt{false sharing} produces a huge increase in the accesses
      to level 3 caches and snoop requests. This means that the first two levels of caches have the data
      \\texttt{invalidated} because some other thread has modified \\textbf{part of it}. That's the cause
      of the increase in memory access time."
    end
  end

  section "Execution time and speedup", special: true
  enumerate do
    question "Complete the following table with the execution
    times of the different versions of dotprod that we provide to
    you. The speed–up has to be computed with respect to the execution
    of the serial version. For each version and number of threads, how
    many executions have you performed?"

    center do
      tabular "| l || c | c | c |" do
        head "version", "1 processor", "8 processors", "speed–up"
        hline

        serial = 0.315
        versions = {
          "mutex_everytime"   => [1.079, 35.447],
          "mutex"             => [0.360, 0.067],
          "vectorsum"         => [0.383, 0.242],
          "vectorsum_padding" => [0.385, 0.069]
        }

        row "dotprod_serial", serial, "-", "1"

        versions.each do |name, times|
          row "dotprod_#{name}", "%.3f" % times[0], "%.3f" % times[1], "%.3f" % [ serial / times.min ] 
        end

        hline
      end
    end

    puts "Two executions for each version and number of threads."
  end
end
